{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177d4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import requests\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce30659",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fetch_github_repositories():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    global most_complex_repo, justification_text\n",
    "    \n",
    "    user_url = url_entry.get()\n",
    "    \n",
    "    # Extracting the GitHub username from the user URL\n",
    "    parsed_url = urlparse(user_url)\n",
    "    username = parsed_url.path.strip(\"/\")\n",
    "    \n",
    "    # Ensure the username is not empty\n",
    "    if not username:\n",
    "        print(\"Invalid GitHub user URL.\")\n",
    "        return\n",
    "    \n",
    "    # API endpoint to fetch user repositories\n",
    "    api_url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Raise exception if request was unsuccessful\n",
    "        repositories = response.json()\n",
    "\n",
    "        # Extracting repository names\n",
    "        repository_names = [repo['name'] for repo in repositories]\n",
    "      \n",
    "        \n",
    "        # Initialize tokenizer and model\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "        \n",
    "        \n",
    "        # Preprocess repository names\n",
    "        def preprocess_repository_names(repository_names):\n",
    "            for repo in repository_names:\n",
    "                repo = repo.strip().lower()  # Convert to lowercase and remove leading/trailing whitespaces\n",
    "                if repo:  # Skip empty names\n",
    "                    yield repo\n",
    "                    \n",
    "        # Process a repository\n",
    "        def process_repository(repository_name):\n",
    "            # Generate a prompt or template based on the repository name\n",
    "            prompt = f\"Evaluate the technical complexity of the repository: {repository_name}. Analyze the code and provide insights on its complexity.\"\n",
    "            \n",
    "            # Tokenize the prompt\n",
    "            input_ids = tokenizer.encode(prompt, add_special_tokens=False, truncation=True, max_length=100, return_tensors=\"pt\")\n",
    "            \n",
    "            # Generate attention mask\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "            # Generate output using the model\n",
    "            with torch.no_grad():\n",
    "                output = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "            # Decode the output\n",
    "            processed_repo = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "            return processed_repo\n",
    "         \n",
    "            \n",
    "        preprocessed_names_generator = preprocess_repository_names(repository_names)\n",
    "        \n",
    "        \n",
    "        # Process and score the preprocessed names\n",
    "        repository_scores = {}\n",
    "        for preprocessed_name in preprocessed_names_generator:\n",
    "            processed_repo = process_repository(preprocessed_name)\n",
    "\n",
    "            # The complexity score is based on the length of the processed repository which in turn is based on output of model.\n",
    "            complexity_score = len(processed_repo)\n",
    "            repository_scores[preprocessed_name] = complexity_score\n",
    "        \n",
    "        # Identify the repository with the highest complexity score\n",
    "        most_complex_repo = max(repository_scores, key=repository_scores.get)\n",
    "        \n",
    "        # Justify the selection using GPT\n",
    "        justification_prompt = f\"Justification for selecting the most technically complex repository: {most_complex_repo}.\"\n",
    "        justification_input_ids = tokenizer.encode(justification_prompt, add_special_tokens=False, truncation=True, max_length=100, return_tensors=\"pt\")\n",
    "        \n",
    "        attention_mask = torch.ones_like(justification_input_ids)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            justification_output = model.generate(input_ids=justification_input_ids, attention_mask=attention_mask, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
    "        \n",
    "        justification_text = tokenizer.decode(justification_output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Update the GUI labels with the values\n",
    "        most_complex_repo_var.set(most_complex_repo)\n",
    "        justification_text_var.set(justification_text)\n",
    "        \n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"An HTTP error occurred: {err}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(f\"An error occurred: {err}\")        \n",
    "        \n",
    "\n",
    "# GUI\n",
    "window = tk.Tk()\n",
    "window.title(\"GitHub Repository Fetcher\")\n",
    "\n",
    "# URL entry\n",
    "url_label = tk.Label(window, text=\"GitHub User URL:\")\n",
    "url_label.pack()\n",
    "url_entry = tk.Entry(window, width=50)\n",
    "url_entry.pack()\n",
    "\n",
    "# Fetch button\n",
    "fetch_button = tk.Button(window, text=\"Fetch Repositories\", command=fetch_github_repositories)\n",
    "fetch_button.pack()\n",
    "\n",
    "# Display repository name\n",
    "repo_label = tk.Label(window, text=\"Most Complex Repository:\")\n",
    "repo_label.pack()\n",
    "\n",
    "most_complex_repo_var = tk.StringVar()\n",
    "repo_name_label = tk.Label(window, textvariable=most_complex_repo_var)\n",
    "repo_name_label.pack()\n",
    "\n",
    "# Display justification\n",
    "justification_label = tk.Label(window, text=\"Justification:\")\n",
    "justification_label.pack()\n",
    "\n",
    "justification_text_var = tk.StringVar()\n",
    "justification_text_label = tk.Label(window, textvariable=justification_text_var, wraplength=400)\n",
    "justification_text_label.pack()\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ee3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
